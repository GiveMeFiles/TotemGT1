<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>TotemGT1.io</title>
    <style>
        body {
            margin: 0;
            background-color: #f0f0f0;
        }
        #ar-container {
            width: 100vw;
            height: 100vh;
            display: flex;
            justify-content: center;
            align-items: center;
        }
        #ar-view {
            width: 100%;
            height: 100%;
        }
    </style>
</head>
<body>
    <div id="ar-container">
        <div id="ar-view"></div>
    </div>
    <script type="module" src="https://cdnjs.cloudflare.com/ajax/libs/three.js/0.163.0/three.module.js"></script>
    <script src="https://cdnjs.cloudflare.com/ajax/libs/ar.js/2.2.2/aframe-ar.js"></script>
    <script>
        function init() {
            // Load the GLB model
            const loader = new THREE.GLTFLoader();
            loader.load('LOGO_GREENTECH250424.glb', (gltf) => {
                const model = gltf.scene;
                model.scale.set(0.5, 0.5, 0.5); // Increased the scale to make the model larger

                // Create the AR scene
                const arScene = new THREEx.ArToolkitSource({
                    sourceType: 'webcam'
                });

                const arCamera = new THREEx.ArToolkitContext({
                    detectionMode: 'mono',
                    patternRatio: 0.5 // Ajustez ce ratio en fonction de la taille de votre QR code
                });

                // Configurez AR.js pour utiliser votre QR code comme marqueur
                const markerControls = new THREEx.ArMarkerControls(arCamera, {
                    type: 'pattern',
                    patternUrl: 'https://github.com/GiveMeFiles/TotemGT1/blob/main/QR.png'
                });

                // Initialize AR context
                arCamera.init(() => {
                    // Create a new scene
                    const scene = new THREE.Scene();
                    scene.add(model);

                    // Create the renderer
                    const renderer = new THREE.WebGLRenderer({
                        canvas: document.getElementById('ar-view'),
                        antialias: true,
                        alpha: true
                    });
                    renderer.setSize(window.innerWidth, window.innerHeight);
                    
                    // Attach the AR context to the camera
                    arCamera.arController.attachPatternDetection(arScene.context);
                    
                    // Render the scene
                    function animate() {
                        requestAnimationFrame(animate);
                        arScene.context.update(arScene.domElement);
                        renderer.render(scene, arCamera.getCamera());
                    }
                    animate();
                });
            });
        }

        // Handle camera permission issues
        navigator.mediaDevices.getUserMedia({ video: true })
            .then(stream => {
                console.log('Camera permission granted');
                init(); // Call init once camera permission is granted
            })
            .catch(error => {
                console.error('Error granting camera permission:', error);
            });
    </script>
</body>
</html>
